{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a850f2b4-96f3-4e8f-9658-9d6902706ca0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# https://qwen.readthedocs.io/en/latest/framework/LlamaIndex.html\n",
    "\n",
    "import torch\n",
    "from llama_index.core import Settings\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "# Set prompt template for generation (optional)\n",
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "\n",
    "def completion_to_prompt(completion):\n",
    "    return f\"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n{completion}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "\n",
    "def messages_to_prompt(messages):\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"system\":\n",
    "            prompt += f\"<|im_start|>system\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"user\":\n",
    "            prompt += f\"<|im_start|>user\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"assistant\":\n",
    "            prompt += f\"<|im_start|>assistant\\n{message.content}<|im_end|>\\n\"\n",
    "\n",
    "    if not prompt.startswith(\"<|im_start|>system\"):\n",
    "        prompt = \"<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n\" + prompt\n",
    "\n",
    "    prompt = prompt + \"<|im_start|>assistant\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def setup(model, tokenizer, embed_model, input_dir = None, input_files = None):\n",
    "    # Set Qwen2.5 as the language model and set generation config\n",
    "    Settings.llm = HuggingFaceLLM(\n",
    "        model_name=model, # \"Qwen/Qwen3-235B-A22B-Instruct-2507\",  # \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        tokenizer_name=tokenizer, # \"Qwen/Qwen3-235B-A22B-Instruct-2507\",  # \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "        context_window=30000,\n",
    "        max_new_tokens=2000,\n",
    "        generate_kwargs={\n",
    "            \"temperature\": 0.7,\n",
    "            \"top_k\": 20,\n",
    "            \"top_p\": 0.8,\n",
    "        },  # {\"temperature\": 0.7, \"top_k\": 50, \"top_p\": 0.95},\n",
    "        messages_to_prompt=messages_to_prompt,\n",
    "        completion_to_prompt=completion_to_prompt,\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "\n",
    "    # Set embedding model\n",
    "    Settings.embed_model = HuggingFaceEmbedding(\n",
    "        model_name=embed_model, # \"BAAI/bge-multilingual-gemma2\"  # \"BAAI/bge-base-en-v1.5\"\n",
    "    )\n",
    "\n",
    "    # Set the size of the text chunk for retrieval\n",
    "    Settings.transformations = [SentenceSplitter(chunk_size=1024)]\n",
    "\n",
    "    from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "\n",
    "    if input_dir is not None:\n",
    "        documents = SimpleDirectoryReader(\n",
    "            input_dir=input_dir\n",
    "        ).load_data()\n",
    "    elif input_files is not None:\n",
    "        documents = SimpleDirectoryReader(\n",
    "            input_files=input_files\n",
    "        ).load_data()\n",
    "        \n",
    "    Settings.index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        embed_model=Settings.embed_model,\n",
    "        transformations=Settings.transformations,\n",
    "    )\n",
    "\n",
    "def query(query_text):\n",
    "    query_engine = Settings.index.as_query_engine()\n",
    "    response = query_engine.query(query_text).response\n",
    "    print(response)\n",
    "    #return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59954d4a-e102-4e67-8283-d2f0a31b58c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5506745d424e49b75af024081d1fdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d99b914703742459206108c009e9c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47afe53851604d5c8a65d40076bf226e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/329 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef79f48600034c69a2e25bbe40742899",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8c26bdb59064025af031b762fd93530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b78adede1a34646879c6cf2b027725a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/897 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a513d3dd2a4942e2ab2fd67a27ca0a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e2be2dcb65484b9933741734a1a566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dc9ef55cf764859bcdb92b8f01a96e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/9.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "620403f75b6c4a508153f58dc046260b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/7.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d7c233bf1684c3087f39560a911134e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/9.90G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563427f25b2745f0a7d327c31077cf6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/9.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fef0d41103d34e4fa12f786f24c02162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "020ddf6fd0d946d794ab78f564bef5f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e1aba71dbf43989fbf4e26b8e7f4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "913f683774fd42d69e094463748b8d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fe195440b547df98f412bdf7cf767c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "968fd88e8529422c8927eb1c3c55e1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46bfb2ef72a4c86a6d5fac74d4b1f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#setup(\n",
    "#    model = \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "#    tokenizer = \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "#    embed_model = \"BAAI/bge-multilingual-gemma2\",\n",
    "#    input_files = [\"../document/saiyuuki.txt\"])\n",
    "\n",
    "#setup(\n",
    "#    model = \"Qwen/Qwen3-235B-A22B-Instruct-2507\",\n",
    "#    tokenizer = \"Qwen/Qwen3-235B-A22B-Instruct-2507\",\n",
    "#    embed_model = \"BAAI/bge-multilingual-gemma2\",\n",
    "#    input_files = [\"../document/saiyuuki.txt\"])\n",
    "\n",
    "setup(\n",
    "    model = \"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    "    tokenizer = \"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    "    embed_model = \"BAAI/bge-multilingual-gemma2\",\n",
    "    input_files = [\"../document/saiyuuki.txt\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaf53937-45fd-4b8a-8e6a-f84823867d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "悟空の飛行方法は、道具を使用せず、自身の法術（呪文）によって実現しています。彼は「念声咒語」を唱え、風雲を駆使して空中を飛行します。文中では「好猴王念声咒语驾阵狂风云头落下」と記されており、これは悟空が呪文を唱えることで風雲を操り、空中を移動していることを示しています。したがって、道具ではなく、自身の修行によって得た能力で飛行しています。\n"
     ]
    }
   ],
   "source": [
    "query(\"悟空の飛行方法を教えてください。道具を使用して飛行しますか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6aefece-4562-47ab-b2cc-23103d057e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沙悟净（さごじょう）は人間ではありません。彼は「卷帘大将（けんれんたいしょう）」という天界の神々しい存在が、天で罪を犯して流沙河（りゅうさが）に堕ち、形を失って妖魔として生きている存在です。彼は観音菩薩によって教化され、法名を「沙悟净」として「沙」を姓として受け、取経の旅に従うことを誓います。したがって、彼は人間ではなく、元は天界の将軍であり、現在は取経の旅に参加する修行者（弟子）として登場しています。\n"
     ]
    }
   ],
   "source": [
    "query(\"沙悟浄は人間でしょうか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deed3d8e-45b3-4b8e-bc96-e91dea72537f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "物語の最後で悟空（孫悟空）は、唐僧（三蔵法師）と共に東土中国へ帰還し、五聖（五人の聖者）として成仏します。彼は長い修行と試練を経て、本来の姿を悟り、真の悟りを得ます。最終的に、彼は仏の位に昇り、法を広める使命を果たすとともに、仲間たちと共に「五聖成真」となり、永遠の悟りを得ます。\n"
     ]
    }
   ],
   "source": [
    "query(\"物語の最後で悟空はどうなりますか？\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75262b6c-09e2-4585-86f2-a0c83656dc51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
